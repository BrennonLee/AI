{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 3202, Spring 2018\n",
    "\n",
    "# Friday 6 April 2018\n",
    "\n",
    "# In-class notebook:  Markov chain Monte Carlo (MCMC)\n",
    "\n",
    "<a id='top'></a>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Your name(s): Brennon Lee\n",
    "\n",
    "<br>\n",
    "\n",
    "* You will submit this to Moodle as **Quizlet 13**.  \n",
    "* Be sure to include **everyone's name that you worked with**. \n",
    "* Note that **everyone must turn in their own copy of the assignment**.\n",
    "\n",
    "---\n",
    "\n",
    "Shortcuts:  [Top](#top) || [Intro](#intro) | [Algorithm](#algo) | [Implementation](#imple) | [Classes](#class) | [Metropolist-Hastings](#mh) | [Inference](#infer) || [Conclusions](#conc)\n",
    "\n",
    "---\n",
    "\n",
    "Before we begin, let's load a few packages that we might find useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "\n",
    "---\n",
    "### Markov chain Monte Carlo\n",
    "\n",
    "Markov chain Monte Carlo (MCMC) is a common and powerful technique to sample from distributions that are a pain in the ass/impossible to write down explicitly (like, actually do the integrals needed).  Part of the power of MCMC is in its ability to **characterize uncertainty** in the things you are trying to estimate.  Let us have a look, shall we?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.thesun.co.uk/wp-content/uploads/2017/10/nintchdbpict000357607366.jpg?strip=all&w=960\" width=\"250\">\n",
    "\n",
    "\n",
    "**Suppose we have a linear model** for the number of squirrels we see on a given day ($y$), as a function of the number of miles we ride a bike that day ($x$).  So the ***true*** process model, based on the unknown true values of the slope and intercept parameters, which we can call $\\alpha^*$ and $\\beta^*$, is:\n",
    "\n",
    "$$y_{true} = \\alpha^* x + \\beta^*$$\n",
    "\n",
    "We can make this more realistic by incorporating some normally-distributed uncertainty, say, with mean 0 and standard deviation $\\sigma$.  Call these uncertain measurements $y_{meas}$:\n",
    "\n",
    "$$y_{meas} = y_{true} + \\epsilon = \\alpha^* x + \\beta^* + \\epsilon$$\n",
    "\n",
    "where $\\epsilon \\sim N(0, \\sigma^2)$ is our normally-distributed measurement error.\n",
    "\n",
    "Now we want to estimate $\\alpha$ and $\\beta$.  Call $\\hat{\\alpha}$ and $\\hat{\\beta}$ our estimates of these parameters.  They lead to a set of estimates of the response, $\\hat{y}$:\n",
    "\n",
    "$$\\hat{y} = \\hat{\\alpha} x + \\hat{\\beta}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "**To start:**\n",
    "* set the random number seed so all our results (at least for this part) will be consistent\n",
    "* set up a grid of $x$ values between 0 and 10 in increments of 0.5, \n",
    "* let $\\alpha^* = 1$ and let $\\beta^* = 10$\n",
    "* let $\\sigma = 1.5$ represent the measurement uncertainty\n",
    "* calculate the true values $y_{true}$ and a set of measured values $y_{meas}$\n",
    "* make a plot of:\n",
    "  * number of miles biked ($x$) versus true number of squirrels seen ($y_{true}$), and\n",
    "  * measured number of squirrels seen ($y_{meas}$)\n",
    "  * include axis labels and a legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113912dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(3202)\n",
    "\n",
    "astar = 1\n",
    "bstar = 10\n",
    "sigma = 1.5\n",
    "x_grid = np.arange(0,10,0.5)\n",
    "y_true = [astar*x + bstar for x in x_grid]\n",
    "\n",
    "# x and y values of our synthetic data set\n",
    "x_meas = np.arange(0,10,0.5)\n",
    "y_meas = [stats.norm.rvs(loc=y, scale=sigma) for y in y_true]\n",
    "\n",
    "plt.plot(x_grid, y_true, label='$y_{true}$')\n",
    "plt.scatter(x_grid, y_meas, color='coral', label='$y_{meas}$')\n",
    "plt.xlabel('Miles biked')\n",
    "plt.ylabel('Squirrels seen')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflection:**  \n",
    "1. What do the values $\\alpha^* = 1$ and $\\beta^* = 10$ mean *physically*?\n",
    "2. How many data points do we have?\n",
    "\n",
    "<br>\n",
    "\n",
    "Of course, we could use good old-fashioned **least squares regression** to get estimates of the parameters $\\alpha$ and $\\beta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope estimate is 0.9106, intercept estimate is 10.3923\n"
     ]
    }
   ],
   "source": [
    "bestfit = stats.linregress(x=x_meas, y=y_meas)\n",
    "print('Slope estimate is {:0.4f}, intercept estimate is {:0.4f}'.format(bestfit.slope,bestfit.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... but that doesn't tell us anything useful about the ***uncertainty*** in those estimates.\n",
    "\n",
    "*(NB: yes, you could get confidence intervals, but Bayesian estimation and inference are better for real-world decision-making. And Artificial Intelligence is all about teaching computers how to make decisions. So here we go!)*\n",
    "\n",
    "<br>\n",
    "\n",
    "So let's use **Markov chain Monte Carlo** to characterize the uncertainty in our estimates of those linear model parameters. To simplify, let's keep $\\beta$ fixed at the least square value from above, and only worry about estimating $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = bestfit.intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='algo'></a>\n",
    "\n",
    "---\n",
    "### Algorithm\n",
    "\n",
    "> **Metropolis-Hastings Algorithm (MCMC):**\n",
    "  Exactly the same as **simulated annealing** with the following modifications:\n",
    "  * save **all** of the previous parameter states because it's a Markov chain, so they all tell you something about your system\n",
    "  * probability of accepting a move at iteration $t$ is the ratio of **posterior scores** for the current and the proposed states:\n",
    "  $$p_{accept} = \\dfrac{\\pi(\\alpha_{new} \\mid y_{meas})}{\\pi(\\alpha_{t} \\mid y_{meas})}$$\n",
    "  where $\\pi(\\alpha \\mid y_{meas})$ is the posterior score for the parameter value $\\alpha$, given the data.\n",
    "    * if we accept the proposed move, then the next $\\alpha_{t+1}$ is set to $\\alpha_{new}$\n",
    "    * if we reject the proposed move, then the next $\\alpha_{t+1}$ is set to $\\alpha_t$ (no change)\n",
    "  * do this for some large number $N$ of iterations ($t=0, 1, 2, \\ldots, N$)\n",
    "  \n",
    "There are a lot of ways to improve and modify the MCMC algorithm, but **this is basically it**.\n",
    "\n",
    "M-H is just one of many MCMC algorithms, but is the most natural for us to use because of its close ties to simulated annealing.\n",
    "\n",
    "<br>\n",
    "\n",
    "**The why:**  If we use $p_{accept}$ as above, then some glorious things occur:\n",
    "1. the sequence of parameter estimates $\\{\\alpha_t\\}_{t=0}^N$ is a Markov chain (we know this already)\n",
    "2. math (not shown) reveals that this Markov chain has a stationary distribution...\n",
    "3. ... that just happens to be **the** posterior distribution $\\pi(\\alpha \\mid y_{meas})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imple'></a>\n",
    "\n",
    "---\n",
    "### Implementation\n",
    "\n",
    "To compute the acceptance probabilities for the Metropolis-Hastings algorithm, we need the posterior scores, which are:\n",
    "\n",
    "$$\\text{posterior score} = \\pi(\\alpha \\mid y_{meas}) = L(y_{meas} \\mid \\alpha) \\times \\pi(\\alpha)$$\n",
    "\n",
    "So, we will need a likelihood function, $L(y_{meas} \\mid \\alpha)$, and a prior distribution for $\\alpha$, $\\pi(\\alpha)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Likelihood function\n",
    "For the likelihood function, we know the data are all normally distributed with mean 0 and standard deviation $\\sigma$. So, similarly to the SLR model problem from the homework, we will use the product of normal distributions for each data point:\n",
    "\n",
    "$$L(y \\mid \\alpha) = \\prod_{i=1}^N f(\\hat{y}_i-y_i \\mid \\mu=0, \\sigma)$$\n",
    "\n",
    "where $f(\\hat{y}_i-y_i \\mid \\mu=0, \\sigma)$ is a normal pdf evaluated at $\\hat{y}_i - y_i$, with mean 0 and standard deviation $\\sigma$, and $\\hat{y} = \\alpha x + \\beta$ (evaluated at the `x_grid` points, and with our fixed value for $\\beta$) (*hint:  see `scipy.stats.norm.pdf`*)\n",
    "\n",
    "Code up a `likelihood` function that takes a single argument `parameter` representing the $\\alpha$ at which we will evaluate our model to obtain $\\hat{y}$ and compare it against $y_{meas}$. Note that this assumes the use of some implicit variables passing into the function, but will keep things a little more tidy.\n",
    "\n",
    "**\"Unit test\":** $~~\\texttt{likelihood}(1.5) \\approx 1.6 \\times 10^{-37}$\n",
    "\n",
    "*If the random number generator seeding is version-dependent, you result might differ. As long as your result is in the ballpark of $10^{-30\\text{something}}$, you are probably fine.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6245683261075742e-37"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def likelihood(parameter):\n",
    "    \n",
    "    # your code goes here\n",
    "    yhat = [parameter *x + beta for x in x_grid]\n",
    "    \n",
    "    prod = 1\n",
    "    for i in range(len(yhat)):\n",
    "        prod *= stats.norm.pdf(x=yhat[i], loc=y_meas[i], scale=sigma)\n",
    "    return prod\n",
    "    \n",
    "    \n",
    "    \n",
    "likelihood(1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior distribution\n",
    "The simplest choice for a prior is use a uniform distribution... So let's do that! \n",
    "\n",
    "We should use a mechanistic understanding of the system we are studying to inform what the upper and lower bounds of our prior range should be. So condsider:  what is a reasonable lower bound on $\\alpha$?\n",
    "\n",
    "$0 \\leq \\alpha \\leq 5$ seems wide enough to capture anything we care about. Define a `prior` function that takes a single `parameter` argument and returns the prior probability for that parameter value. Again, my hair has gone a little bit gray because of the implicit function input...\n",
    "\n",
    "**\"Unit test\":** $~~ \\texttt{prior}(1.5) = 0.2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ub = 5\n",
    "lb = 0\n",
    "\n",
    "def prior(parameter):\n",
    "    \n",
    "    # your code goes here\n",
    "    if lb <= parameter <= ub:\n",
    "        return 1/(ub-lb)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "prior(1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posterior score\n",
    "Now for the sake of compactness, define a `posterior` function that returns the posterior score:\n",
    "\n",
    "$$\\texttt{posterior}(\\alpha) = \\texttt{likelihood}(\\alpha) \\times \\texttt{prior}(\\alpha)$$\n",
    "\n",
    "You can save some run-time by coding the `likelihood` function to only run if the `prior` function returns a nonzero probability.  If `prior`($\\alpha$)=0, then we know `posterior`($\\alpha$) is going to be 0 no matter what the `likelihood` function returns.  This doesn't matter much for this simple model, but it scales up very nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(parameter):\n",
    "    \n",
    "    # your code goes here\n",
    "    return likelihood(parameter) * prior(parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"Unit tests\"**:\n",
    "* What should `posterior(-6)` equal? Check this.\n",
    "* Check that `posterior(1.5)` = the product of your results above for `likelihood(1.5)` and `prior(1.5)`\n",
    "\n",
    "Since `posterior` is going to be returning some very small values, in practice we will use the `log(posterior)` values for this algorithm. But **Future You** can worry about that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "3.2491366522151486e-38\n"
     ]
    }
   ],
   "source": [
    "print(posterior(-6))\n",
    "print(posterior(1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='class'></a>\n",
    "\n",
    "---\n",
    "### Class structures\n",
    "\n",
    "#### `State` class from Local Search\n",
    "Just like for Simulated Annealing (and Hill-Climbing) we should keep track of our states ($\\alpha$ values) and the associated posterior scores.\n",
    "\n",
    "This is just like our Local Search, where now the `posterior` function is our objective function, which we want to maximize. The beauty of MCMC is that we are maximizing it ***in light of the uncertainties in our model and data***.\n",
    "\n",
    "**Define** an initial parameter estimate for $\\alpha$. The least squares regression value for $\\alpha$ above is a very reasonable first guess! **And create** an associated initial state for our MCMC algorithm to start from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, state, value):\n",
    "        self.state = state\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Problem` class... also from Local Search\n",
    "\n",
    "Below is the code for the Simulated Annealing Problem sub-class, actually copy-pasted from my Local Search notebook and with a couple variable names changed.\n",
    "\n",
    "**Define** a `ProblemMCMC` object. Use the initial state and `posterior` function from above, and use the stepsize 0.05 to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProblemMCMC:        \n",
    "    def __init__(self, initial, posterior, stepsize):\n",
    "        self.current = initial\n",
    "        self.post = posterior\n",
    "        self.stepsize = stepsize\n",
    "        \n",
    "    def random_move(self):\n",
    "        next_move = stats.multivariate_normal.rvs(self.current.state, self.stepsize)\n",
    "        return next_move, self.post(next_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mh'></a>\n",
    "\n",
    "---\n",
    "### Metropolis-Hastings algorithm\n",
    "\n",
    "Below is pseudocode for the Metropolis-Hastings algorithm, which actually *does* the MCMC sampling. The function `mcmc` takes as input a `ProblemMCMC` class object, called `problem`, and a positive integer number of iterations to run the algorithm, `n_iter`.\n",
    "\n",
    "Fill in the rest of the code!  Your simulated annealing codes can be used as a very helpful guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mcmc(problem, n_iter):\n",
    "    \n",
    "    # want to keep growing these lists to track the parameter estimates\n",
    "    parameters = [problem.current.state]\n",
    "    posterior = [problem.current.value]\n",
    "    \n",
    "    for t in range(n_iter):\n",
    "\n",
    "        # Propose a new state\n",
    "        propsed_state, next_post = problem.random_move()\n",
    "        # Calculate the acceptance probability\n",
    "        \n",
    "        p_accept = self.post(problem.current, problem.post) / self.post(proposed_state, next_post)\n",
    "        # If p_accept >= 1\n",
    "            # Add the proposed parameter to the end of the list of parameters\n",
    "            \n",
    "            # Add the corresponding posterior score to the end of that list too\n",
    "\n",
    "        # If p_accept < 1\n",
    "            # Accept with probability p_accept\n",
    "            \n",
    "            # If you accept:\n",
    "                # Add the proposed parameter to the end of the list `parameters`\n",
    "                \n",
    "                # Add the corresponding posterior score to the end of that list too\n",
    "\n",
    "            # If you reject:\n",
    "                # Add another copy of the current parameter value to the end of the list `parameters`\n",
    "                \n",
    "                # Add the corresponding posterior score to the end of that list too\n",
    "\n",
    "\n",
    "    return # the `parameters` and `posterior` scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As a first step,** make sure your implementation is working. Run 100 iterations and save the parameter estimates and the corresponding posterior scores.\n",
    "\n",
    "When plotted as a line, the parameter estimates as a function of iteration should look like the following, which is called a **trace plot** or **history plot** of the Markov chain:\n",
    "\n",
    "![trace plot](http://www.cs.colorado.edu/~tonyewong/home/resources/example_trace_plot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have 100 iterations running smoothly and reproducing (approximately) the plot above, run 4000 iterations and generate a history plot. (*note:  this might take a few seconds*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your plot should display the **hairy caterpillar** look of a well-mixed Markov chain.  If it's right, you will know it because the history plot will resemble a hairy caterpillar (and Googling 'markov chain hairy caterpillar' will return a lot of appropriate pictures, as well as some cute critters).\n",
    "\n",
    "#### Acceptance ratio\n",
    "But another, more sciency, way that we can assess Markov chain quality is by calculating the **acceptance ratio**.  Come up with a way to calculate the proportion of parameter proposals that were accepted.  \n",
    "* One obvious way is to modify your `mcmc` codes above to return this as an output.\n",
    "* Another way you can swiftly do this post-processing is to use the `numpy` `diff` function.\n",
    "\n",
    "**Print out** the acceptance rate for your Markov chain simulation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you know if your acceptane ratio is 'correct'?\n",
    "* For many parameters (think > 10), the optimal acceptance rate is about 23.4%\n",
    "* For one parameter (our case!), the optimal acceptance rate is about 44%\n",
    "\n",
    "<br>\n",
    "\n",
    "The acceptance rate for your Markov chain is almost certainly not 44%.  This is related to the **stepsize** used:\n",
    "* if you accept too few proposals, then your stepsize is too large (because you're leaping over good ones)\n",
    "* if you accept too many proposals, then your stepsize is too small (because you are too timid in your exploration)\n",
    "\n",
    "**Play around** with the `stepsize` input to the `ProblemMCMC` object and see if you can get something closer to 44%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a/ id='infer'></a>\n",
    "\n",
    "---\n",
    "### Posterior inference\n",
    "Now that our acceptance rate is about right, we can use the resulting Markov chain to make inferences regarding the parameter $\\alpha$.\n",
    "\n",
    "We only care about the Markov chain once it has converged to the **stationary distribution** though, which takes some time.  So we need to throw away the period during which it is still converging.  This process is called **burn-in**.\n",
    "\n",
    "Throw out the first half of your Markov chain for burn-in, and save the last half (2000 iterations) for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms\n",
    "... are one way to ***qualitatively*** display and characterize uncertainty in our model parameter.  Make a histogram of our posterior parameter estimates for $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credible intervals\n",
    "... are a way to ***quantitatively*** characterize our parametric uncertainty.  Calculate and print to the screen the 90% credible interval, which is the 5-95% quantile range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Projections\n",
    "\n",
    "It is possible that you would use MCMC to characterize uncertainty and that would be it.  But another big strength of MCMC is our ability now to generate a **posterior ensemble** and use it to make projections out-of-sample.  For example, our data did not include any bike rides longer than 10 miles.  So a natural question is: *what is our best estimate for the number of squirrels we would see on a 15-mile bike ride?* and equally importantly: *what is the uncertainty in that estimate?*\n",
    "\n",
    "**Estimate** the number of squirrels you would see on a 15-mile bike ride using the 2000 posterior samples for $\\alpha$.\n",
    "* create a histogram of your estimates of $y(15)$\n",
    "* calculate and print the 5-95% credible range for $y(15)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a/ id='conc'></a>\n",
    "\n",
    "---\n",
    "### Important take-aways:\n",
    "\n",
    "1. The Metropolis-Hasting MCMC algorithm is just simulated annealing done in a clever way...\n",
    "2. that allows us to sample from the **posterior distribution** of model parameters, **given the data**.\n",
    "6. Acceptance rate of about 23% is optimal only for lots parameters. For our single parameter, it's more like 44%.\n",
    "4. We can use MCMC and credible intervals/histograms to **characterize** and **quantify** uncertainty in both our parameters and predictions.\n",
    "\n",
    "<br>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
